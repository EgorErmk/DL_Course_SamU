{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "device = '/device:gpu:1'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 32, 32, 3) (64,)\n",
      "1 (64, 32, 32, 3) (64,)\n",
      "2 (64, 32, 32, 3) (64,)\n",
      "3 (64, 32, 32, 3) (64,)\n",
      "4 (64, 32, 32, 3) (64,)\n",
      "5 (64, 32, 32, 3) (64,)\n",
      "6 (64, 32, 32, 3) (64,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети. \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()        \n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device('/device:gpu:0'):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации. \n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU \n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU \n",
    "5. Полносвязный слой \n",
    "6. Функция активации Softmax \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=channel_1,kernel_size=(5,5), activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=channel_2,kernel_size=(3,3), activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc3 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 3, 32, 32))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False,print_every = 100):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "\n",
    "        \n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.0009891986846924, Accuracy: 10.9375, Val Loss: 2.950167417526245, Val Accuracy: 12.700000762939453\n",
      "Iteration 100, Epoch 1, Loss: 2.254225969314575, Accuracy: 28.434404373168945, Val Loss: 1.9220973253250122, Val Accuracy: 36.79999923706055\n",
      "Iteration 200, Epoch 1, Loss: 2.084908962249756, Accuracy: 32.22947692871094, Val Loss: 1.847917914390564, Val Accuracy: 39.599998474121094\n",
      "Iteration 300, Epoch 1, Loss: 2.0045981407165527, Accuracy: 34.115447998046875, Val Loss: 1.9031970500946045, Val Accuracy: 36.70000076293945\n",
      "Iteration 400, Epoch 1, Loss: 1.9358948469161987, Accuracy: 35.727088928222656, Val Loss: 1.7293710708618164, Val Accuracy: 41.70000076293945\n",
      "Iteration 500, Epoch 1, Loss: 1.8904688358306885, Accuracy: 36.72343063354492, Val Loss: 1.6524511575698853, Val Accuracy: 44.20000076293945\n",
      "Iteration 600, Epoch 1, Loss: 1.8595736026763916, Accuracy: 37.720985412597656, Val Loss: 1.6723371744155884, Val Accuracy: 43.39999771118164\n",
      "Iteration 700, Epoch 1, Loss: 1.8340216875076294, Accuracy: 38.48073959350586, Val Loss: 1.634570837020874, Val Accuracy: 44.10000228881836\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 . \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.01434326171875, Accuracy: 20.3125, Val Loss: 5.303304672241211, Val Accuracy: 13.0\n",
      "Iteration 10, Epoch 1, Loss: 3.14461612701416, Accuracy: 18.323863983154297, Val Loss: 2.2343220710754395, Val Accuracy: 20.399999618530273\n",
      "Iteration 20, Epoch 1, Loss: 2.6898016929626465, Accuracy: 20.610118865966797, Val Loss: 2.1409313678741455, Val Accuracy: 24.100000381469727\n",
      "Iteration 30, Epoch 1, Loss: 2.4940526485443115, Accuracy: 22.731855392456055, Val Loss: 2.02899169921875, Val Accuracy: 30.100000381469727\n",
      "Iteration 40, Epoch 1, Loss: 2.368687629699707, Accuracy: 25.15243911743164, Val Loss: 1.9413877725601196, Val Accuracy: 33.19999694824219\n",
      "Iteration 50, Epoch 1, Loss: 2.278085947036743, Accuracy: 26.072301864624023, Val Loss: 1.906837821006775, Val Accuracy: 32.10000228881836\n",
      "Iteration 60, Epoch 1, Loss: 2.2042455673217773, Accuracy: 27.51024627685547, Val Loss: 1.8513766527175903, Val Accuracy: 35.70000076293945\n",
      "Iteration 70, Epoch 1, Loss: 2.1506717205047607, Accuracy: 28.587146759033203, Val Loss: 1.8067336082458496, Val Accuracy: 38.60000228881836\n",
      "Iteration 80, Epoch 1, Loss: 2.108633279800415, Accuracy: 29.6489200592041, Val Loss: 1.7833818197250366, Val Accuracy: 38.60000228881836\n",
      "Iteration 90, Epoch 1, Loss: 2.065800428390503, Accuracy: 30.631866455078125, Val Loss: 1.761597752571106, Val Accuracy: 39.29999923706055\n",
      "Iteration 100, Epoch 1, Loss: 2.025268316268921, Accuracy: 31.52846336364746, Val Loss: 1.7275322675704956, Val Accuracy: 40.79999923706055\n",
      "Iteration 110, Epoch 1, Loss: 1.9945847988128662, Accuracy: 32.33389663696289, Val Loss: 1.7325541973114014, Val Accuracy: 39.79999923706055\n",
      "Iteration 120, Epoch 1, Loss: 1.9691126346588135, Accuracy: 32.96746063232422, Val Loss: 1.6540628671646118, Val Accuracy: 43.79999923706055\n",
      "Iteration 130, Epoch 1, Loss: 1.9440380334854126, Accuracy: 33.623565673828125, Val Loss: 1.635467767715454, Val Accuracy: 45.10000228881836\n",
      "Iteration 140, Epoch 1, Loss: 1.9236747026443481, Accuracy: 34.286346435546875, Val Loss: 1.6296107769012451, Val Accuracy: 44.400001525878906\n",
      "Iteration 150, Epoch 1, Loss: 1.9022917747497559, Accuracy: 34.985511779785156, Val Loss: 1.6611391305923462, Val Accuracy: 43.599998474121094\n",
      "Iteration 160, Epoch 1, Loss: 1.8860212564468384, Accuracy: 35.423133850097656, Val Loss: 1.5944056510925293, Val Accuracy: 45.20000076293945\n",
      "Iteration 170, Epoch 1, Loss: 1.8702083826065063, Accuracy: 35.96491241455078, Val Loss: 1.5839834213256836, Val Accuracy: 45.10000228881836\n",
      "Iteration 180, Epoch 1, Loss: 1.8532131910324097, Accuracy: 36.38639450073242, Val Loss: 1.6065490245819092, Val Accuracy: 44.80000305175781\n",
      "Iteration 190, Epoch 1, Loss: 1.838523030281067, Accuracy: 36.83736801147461, Val Loss: 1.5770872831344604, Val Accuracy: 46.599998474121094\n",
      "Iteration 200, Epoch 1, Loss: 1.8289743661880493, Accuracy: 37.01803207397461, Val Loss: 1.5559158325195312, Val Accuracy: 46.099998474121094\n",
      "Iteration 210, Epoch 1, Loss: 1.8182413578033447, Accuracy: 37.31487274169922, Val Loss: 1.6006197929382324, Val Accuracy: 44.80000305175781\n",
      "Iteration 220, Epoch 1, Loss: 1.805495262145996, Accuracy: 37.64140319824219, Val Loss: 1.5639042854309082, Val Accuracy: 47.29999923706055\n",
      "Iteration 230, Epoch 1, Loss: 1.7947269678115845, Accuracy: 37.878787994384766, Val Loss: 1.525018334388733, Val Accuracy: 47.60000228881836\n",
      "Iteration 240, Epoch 1, Loss: 1.7845350503921509, Accuracy: 38.193721771240234, Val Loss: 1.5275460481643677, Val Accuracy: 47.5\n",
      "Iteration 250, Epoch 1, Loss: 1.776232123374939, Accuracy: 38.45244216918945, Val Loss: 1.523531436920166, Val Accuracy: 46.29999923706055\n",
      "Iteration 260, Epoch 1, Loss: 1.7652748823165894, Accuracy: 38.78711700439453, Val Loss: 1.5008066892623901, Val Accuracy: 47.900001525878906\n",
      "Iteration 270, Epoch 1, Loss: 1.755097508430481, Accuracy: 38.99907684326172, Val Loss: 1.4951329231262207, Val Accuracy: 49.70000076293945\n",
      "Iteration 280, Epoch 1, Loss: 1.7474137544631958, Accuracy: 39.190391540527344, Val Loss: 1.4657700061798096, Val Accuracy: 50.19999694824219\n",
      "Iteration 290, Epoch 1, Loss: 1.7386384010314941, Accuracy: 39.4544677734375, Val Loss: 1.4734348058700562, Val Accuracy: 50.400001525878906\n",
      "Iteration 300, Epoch 1, Loss: 1.7288633584976196, Accuracy: 39.78924560546875, Val Loss: 1.4714910984039307, Val Accuracy: 50.70000457763672\n",
      "Iteration 310, Epoch 1, Loss: 1.7205480337142944, Accuracy: 40.077369689941406, Val Loss: 1.4591549634933472, Val Accuracy: 49.0\n",
      "Iteration 320, Epoch 1, Loss: 1.7139487266540527, Accuracy: 40.33781433105469, Val Loss: 1.4613338708877563, Val Accuracy: 49.29999923706055\n",
      "Iteration 330, Epoch 1, Loss: 1.7044577598571777, Accuracy: 40.658042907714844, Val Loss: 1.4526690244674683, Val Accuracy: 49.70000076293945\n",
      "Iteration 340, Epoch 1, Loss: 1.6961747407913208, Accuracy: 40.90909194946289, Val Loss: 1.4801948070526123, Val Accuracy: 49.599998474121094\n",
      "Iteration 350, Epoch 1, Loss: 1.688948631286621, Accuracy: 41.05234909057617, Val Loss: 1.4556392431259155, Val Accuracy: 49.29999923706055\n",
      "Iteration 360, Epoch 1, Loss: 1.682282567024231, Accuracy: 41.34349060058594, Val Loss: 1.4224135875701904, Val Accuracy: 50.099998474121094\n",
      "Iteration 370, Epoch 1, Loss: 1.6720174551010132, Accuracy: 41.65684127807617, Val Loss: 1.4714120626449585, Val Accuracy: 49.5\n",
      "Iteration 380, Epoch 1, Loss: 1.6646020412445068, Accuracy: 41.908626556396484, Val Loss: 1.40415358543396, Val Accuracy: 52.10000228881836\n",
      "Iteration 390, Epoch 1, Loss: 1.656277060508728, Accuracy: 42.19948959350586, Val Loss: 1.4435745477676392, Val Accuracy: 50.400001525878906\n",
      "Iteration 400, Epoch 1, Loss: 1.6491248607635498, Accuracy: 42.409603118896484, Val Loss: 1.4296866655349731, Val Accuracy: 49.20000076293945\n",
      "Iteration 410, Epoch 1, Loss: 1.642529845237732, Accuracy: 42.59808349609375, Val Loss: 1.4235782623291016, Val Accuracy: 49.39999771118164\n",
      "Iteration 420, Epoch 1, Loss: 1.6367071866989136, Accuracy: 42.77018737792969, Val Loss: 1.4058018922805786, Val Accuracy: 51.599998474121094\n",
      "Iteration 430, Epoch 1, Loss: 1.6304233074188232, Accuracy: 42.959686279296875, Val Loss: 1.4448082447052002, Val Accuracy: 49.900001525878906\n",
      "Iteration 440, Epoch 1, Loss: 1.625182032585144, Accuracy: 43.12287139892578, Val Loss: 1.4001789093017578, Val Accuracy: 51.70000076293945\n",
      "Iteration 450, Epoch 1, Loss: 1.6202462911605835, Accuracy: 43.316932678222656, Val Loss: 1.4214930534362793, Val Accuracy: 49.099998474121094\n",
      "Iteration 460, Epoch 1, Loss: 1.6144639253616333, Accuracy: 43.482242584228516, Val Loss: 1.387345790863037, Val Accuracy: 52.20000076293945\n",
      "Iteration 470, Epoch 1, Loss: 1.6081273555755615, Accuracy: 43.70023727416992, Val Loss: 1.4554057121276855, Val Accuracy: 48.69999694824219\n",
      "Iteration 480, Epoch 1, Loss: 1.6030019521713257, Accuracy: 43.85070037841797, Val Loss: 1.4145249128341675, Val Accuracy: 49.599998474121094\n",
      "Iteration 490, Epoch 1, Loss: 1.5980989933013916, Accuracy: 44.06504821777344, Val Loss: 1.377584457397461, Val Accuracy: 51.099998474121094\n",
      "Iteration 500, Epoch 1, Loss: 1.593636155128479, Accuracy: 44.24588394165039, Val Loss: 1.3838565349578857, Val Accuracy: 50.099998474121094\n",
      "Iteration 510, Epoch 1, Loss: 1.590070366859436, Accuracy: 44.3798942565918, Val Loss: 1.3957343101501465, Val Accuracy: 50.400001525878906\n",
      "Iteration 520, Epoch 1, Loss: 1.587101936340332, Accuracy: 44.442779541015625, Val Loss: 1.3841376304626465, Val Accuracy: 52.39999771118164\n",
      "Iteration 530, Epoch 1, Loss: 1.5843369960784912, Accuracy: 44.50918197631836, Val Loss: 1.3767307996749878, Val Accuracy: 53.500003814697266\n",
      "Iteration 540, Epoch 1, Loss: 1.579869270324707, Accuracy: 44.7002067565918, Val Loss: 1.3599061965942383, Val Accuracy: 53.20000076293945\n",
      "Iteration 550, Epoch 1, Loss: 1.5761972665786743, Accuracy: 44.807735443115234, Val Loss: 1.3727571964263916, Val Accuracy: 51.599998474121094\n",
      "Iteration 560, Epoch 1, Loss: 1.5723583698272705, Accuracy: 44.9170036315918, Val Loss: 1.367702841758728, Val Accuracy: 52.60000228881836\n",
      "Iteration 570, Epoch 1, Loss: 1.5681120157241821, Accuracy: 45.071693420410156, Val Loss: 1.3506991863250732, Val Accuracy: 53.39999771118164\n",
      "Iteration 580, Epoch 1, Loss: 1.5643070936203003, Accuracy: 45.16996383666992, Val Loss: 1.3462636470794678, Val Accuracy: 53.10000228881836\n",
      "Iteration 590, Epoch 1, Loss: 1.5608655214309692, Accuracy: 45.27812957763672, Val Loss: 1.3614219427108765, Val Accuracy: 52.10000228881836\n",
      "Iteration 600, Epoch 1, Loss: 1.5579779148101807, Accuracy: 45.36969757080078, Val Loss: 1.3413249254226685, Val Accuracy: 52.79999923706055\n",
      "Iteration 610, Epoch 1, Loss: 1.55332350730896, Accuracy: 45.53242492675781, Val Loss: 1.333030343055725, Val Accuracy: 54.10000228881836\n",
      "Iteration 620, Epoch 1, Loss: 1.550119161605835, Accuracy: 45.67481994628906, Val Loss: 1.355210781097412, Val Accuracy: 52.39999771118164\n",
      "Iteration 630, Epoch 1, Loss: 1.5466324090957642, Accuracy: 45.79536437988281, Val Loss: 1.3304550647735596, Val Accuracy: 53.500003814697266\n",
      "Iteration 640, Epoch 1, Loss: 1.5436900854110718, Accuracy: 45.90239715576172, Val Loss: 1.3451372385025024, Val Accuracy: 53.60000228881836\n",
      "Iteration 650, Epoch 1, Loss: 1.5408328771591187, Accuracy: 45.98694610595703, Val Loss: 1.340919017791748, Val Accuracy: 52.29999923706055\n",
      "Iteration 660, Epoch 1, Loss: 1.5374386310577393, Accuracy: 46.10202407836914, Val Loss: 1.3272160291671753, Val Accuracy: 52.60000228881836\n",
      "Iteration 670, Epoch 1, Loss: 1.5342605113983154, Accuracy: 46.21134567260742, Val Loss: 1.3591392040252686, Val Accuracy: 52.60000228881836\n",
      "Iteration 680, Epoch 1, Loss: 1.5318621397018433, Accuracy: 46.26927185058594, Val Loss: 1.336102843284607, Val Accuracy: 55.099998474121094\n",
      "Iteration 690, Epoch 1, Loss: 1.528812289237976, Accuracy: 46.39562225341797, Val Loss: 1.3288530111312866, Val Accuracy: 54.400001525878906\n",
      "Iteration 700, Epoch 1, Loss: 1.5264840126037598, Accuracy: 46.49385070800781, Val Loss: 1.3695132732391357, Val Accuracy: 50.900001525878906\n",
      "Iteration 710, Epoch 1, Loss: 1.5227895975112915, Accuracy: 46.60908889770508, Val Loss: 1.2961502075195312, Val Accuracy: 55.5\n",
      "Iteration 720, Epoch 1, Loss: 1.5186904668807983, Accuracy: 46.78181457519531, Val Loss: 1.3370153903961182, Val Accuracy: 53.89999771118164\n",
      "Iteration 730, Epoch 1, Loss: 1.5160921812057495, Accuracy: 46.85576248168945, Val Loss: 1.3297375440597534, Val Accuracy: 54.900001525878906\n",
      "Iteration 740, Epoch 1, Loss: 1.5126900672912598, Accuracy: 47.007843017578125, Val Loss: 1.288123607635498, Val Accuracy: 54.599998474121094\n",
      "Iteration 750, Epoch 1, Loss: 1.5104756355285645, Accuracy: 47.07265090942383, Val Loss: 1.3258280754089355, Val Accuracy: 54.20000076293945\n",
      "Iteration 760, Epoch 1, Loss: 1.5073682069778442, Accuracy: 47.189144134521484, Val Loss: 1.2856987714767456, Val Accuracy: 56.69999694824219\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1,channel_2,num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,nesterov=True, momentum=0.9)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn,print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 47s 61ms/step - loss: 1.5024 - sparse_categorical_accuracy: 0.4722\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model_init_fn()\n",
    "model.compile(optimizer=optimizer_init_fn(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
    "\n",
    "# Train the model\n",
    "with tf.device(device):\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[47,  5,  9,  3,  3,  0,  1,  5, 10,  4],\n",
       "       [ 4, 70,  0,  5,  5,  1,  5,  2,  4, 23],\n",
       "       [ 2,  0, 26,  8, 26,  7,  1,  4,  5,  0],\n",
       "       [ 4,  1,  7, 39, 16, 23,  5,  9,  1,  7],\n",
       "       [ 2,  0,  7,  3, 45,  2,  2, 15,  2,  0],\n",
       "       [ 1,  0,  9, 21, 10, 43,  2, 10,  1,  1],\n",
       "       [ 0,  2,  6, 11, 22,  4, 49,  5,  0,  3],\n",
       "       [ 1,  0,  2,  6, 10,  7,  0, 73,  2,  6],\n",
       "       [ 7,  5,  0,  2,  4,  0,  0,  1, 88,  6],\n",
       "       [ 5, 10,  1,  0,  2,  1,  1,  7,  8, 70]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "predicted_labels = model.predict(X_val,verbose=0)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# Print the predicted labels for the test data\n",
    "print(accuracy_score(y_val,predicted_labels))\n",
    "confusion_matrix(y_val, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.0009891986846924, Accuracy: 10.9375, Val Loss: 2.950167417526245, Val Accuracy: 12.700000762939453\n",
      "Iteration 100, Epoch 1, Loss: 2.254225969314575, Accuracy: 28.434404373168945, Val Loss: 1.9220973253250122, Val Accuracy: 36.79999923706055\n",
      "Iteration 200, Epoch 1, Loss: 2.084908962249756, Accuracy: 32.22947692871094, Val Loss: 1.847917914390564, Val Accuracy: 39.599998474121094\n",
      "Iteration 300, Epoch 1, Loss: 2.0045981407165527, Accuracy: 34.115447998046875, Val Loss: 1.9031970500946045, Val Accuracy: 36.70000076293945\n",
      "Iteration 400, Epoch 1, Loss: 1.9358948469161987, Accuracy: 35.727088928222656, Val Loss: 1.7293710708618164, Val Accuracy: 41.70000076293945\n",
      "Iteration 500, Epoch 1, Loss: 1.8904688358306885, Accuracy: 36.72343063354492, Val Loss: 1.6524511575698853, Val Accuracy: 44.20000076293945\n",
      "Iteration 600, Epoch 1, Loss: 1.8595736026763916, Accuracy: 37.720985412597656, Val Loss: 1.6723371744155884, Val Accuracy: 43.39999771118164\n",
      "Iteration 700, Epoch 1, Loss: 1.8340216875076294, Accuracy: 38.48073959350586, Val Loss: 1.634570837020874, Val Accuracy: 44.10000228881836\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (32, 32, 3)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 37s 48ms/step - loss: 1.8244 - sparse_categorical_accuracy: 0.3892 - val_loss: 1.6787 - val_sparse_categorical_accuracy: 0.4360\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.6618 - sparse_categorical_accuracy: 0.4315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6618281602859497, 0.43149998784065247]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.01434326171875, Accuracy: 20.3125, Val Loss: 2.7612833976745605, Val Accuracy: 10.40000057220459\n",
      "Iteration 100, Epoch 1, Loss: 2.034374237060547, Accuracy: 28.94492530822754, Val Loss: 1.822700023651123, Val Accuracy: 36.5\n",
      "Iteration 200, Epoch 1, Loss: 1.8982499837875366, Accuracy: 33.861942291259766, Val Loss: 1.6933594942092896, Val Accuracy: 42.39999771118164\n",
      "Iteration 300, Epoch 1, Loss: 1.822676420211792, Accuracy: 36.28529739379883, Val Loss: 1.6378499269485474, Val Accuracy: 45.20000076293945\n",
      "Iteration 400, Epoch 1, Loss: 1.758608341217041, Accuracy: 38.54426574707031, Val Loss: 1.5576257705688477, Val Accuracy: 47.900001525878906\n",
      "Iteration 500, Epoch 1, Loss: 1.710456371307373, Accuracy: 40.1415901184082, Val Loss: 1.5393526554107666, Val Accuracy: 46.79999923706055\n",
      "Iteration 600, Epoch 1, Loss: 1.6790730953216553, Accuracy: 41.17876434326172, Val Loss: 1.4903515577316284, Val Accuracy: 49.099998474121094\n",
      "Iteration 700, Epoch 1, Loss: 1.6501144170761108, Accuracy: 42.1875, Val Loss: 1.4470629692077637, Val Accuracy: 51.099998474121094\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    input_shape = (32, 32, 3)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(filters=channel_1,kernel_size=(5,5),input_shape = input_shape, activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer),\n",
    "        tf.keras.layers.Conv2D(filters=channel_2,kernel_size=(3,3), activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer),                           \n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,nesterov=True, momentum=0.9)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 49s 64ms/step - loss: 1.5784 - sparse_categorical_accuracy: 0.4446 - val_loss: 1.3192 - val_sparse_categorical_accuracy: 0.5530\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3238 - sparse_categorical_accuracy: 0.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3238213062286377, 0.5311999917030334]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры. \n",
    "\n",
    "Ниже представлен пример для полносвязной сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ralph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "    \n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "    \n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.8097662925720215, Accuracy: 10.9375, Val Loss: 2.8096046447753906, Val Accuracy: 12.899999618530273\n",
      "Iteration 100, Epoch 1, Loss: 2.246824264526367, Accuracy: 28.38799285888672, Val Loss: 1.8979687690734863, Val Accuracy: 37.0\n",
      "Iteration 200, Epoch 1, Loss: 2.085395336151123, Accuracy: 32.50932693481445, Val Loss: 1.8692342042922974, Val Accuracy: 38.80000305175781\n",
      "Iteration 300, Epoch 1, Loss: 2.006624698638916, Accuracy: 34.219268798828125, Val Loss: 1.8839194774627686, Val Accuracy: 36.79999923706055\n",
      "Iteration 400, Epoch 1, Loss: 1.936090111732483, Accuracy: 36.023223876953125, Val Loss: 1.7358767986297607, Val Accuracy: 41.70000076293945\n",
      "Iteration 500, Epoch 1, Loss: 1.8893674612045288, Accuracy: 36.988525390625, Val Loss: 1.6298576593399048, Val Accuracy: 43.29999923706055\n",
      "Iteration 600, Epoch 1, Loss: 1.857507348060608, Accuracy: 37.8483772277832, Val Loss: 1.6857619285583496, Val Accuracy: 41.5\n",
      "Iteration 700, Epoch 1, Loss: 1.832075595855713, Accuracy: 38.59218978881836, Val Loss: 1.6358929872512817, Val Accuracy: 44.10000228881836\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут). \n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        # self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        # self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        # self.conv2 = tf.keras.layers.Conv2D(filters=16,kernel_size=3, activation='relu',\n",
    "        #                            kernel_initializer=initializer)\n",
    "        # self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        # self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        # self.conv3 = tf.keras.layers.Conv2D(filters=16,kernel_size=3, activation='relu',\n",
    "        #                            kernel_initializer=initializer)\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.pool = tf.keras.layers.MaxPooling2D((6, 6))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc2 = tf.keras.layers.Dense(400, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc3 = tf.keras.layers.Dense(400, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc4 = tf.keras.layers.Dense(400, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc5 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1(x)\n",
    "        # x = self.bn2(x)\n",
    "        # x = self.conv2(x)        \n",
    "        # x = self.bn3(x)\n",
    "        # x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)        \n",
    "        x = self.fc4(x)\n",
    "        x = self.fc5(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "        return x\n",
    "\n",
    "\n",
    "print_every = 700\n",
    "num_epochs = 10\n",
    "\n",
    "model = CustomConvNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CustomConvNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 5e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "\n",
    "#train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите все эксперименты, результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "700/700 [==============================] - 30s 41ms/step - loss: 1.3705 - sparse_categorical_accuracy: 0.5218 - val_loss: 1.1259 - val_sparse_categorical_accuracy: 0.6200\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 26s 37ms/step - loss: 1.0356 - sparse_categorical_accuracy: 0.6408 - val_loss: 0.9930 - val_sparse_categorical_accuracy: 0.6600\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 26s 37ms/step - loss: 0.8963 - sparse_categorical_accuracy: 0.6896 - val_loss: 0.9839 - val_sparse_categorical_accuracy: 0.6700\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 25s 36ms/step - loss: 0.7879 - sparse_categorical_accuracy: 0.7291 - val_loss: 0.9961 - val_sparse_categorical_accuracy: 0.6720\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.7057 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.9338 - val_sparse_categorical_accuracy: 0.6940\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.6318 - sparse_categorical_accuracy: 0.7837 - val_loss: 0.9495 - val_sparse_categorical_accuracy: 0.6900\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 25s 36ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.8064 - val_loss: 1.0408 - val_sparse_categorical_accuracy: 0.6760\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 22s 32ms/step - loss: 0.5289 - sparse_categorical_accuracy: 0.8195 - val_loss: 1.0432 - val_sparse_categorical_accuracy: 0.6820\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 24s 34ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.8399 - val_loss: 1.0489 - val_sparse_categorical_accuracy: 0.6990\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 26s 37ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8550 - val_loss: 1.1273 - val_sparse_categorical_accuracy: 0.6920\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0451 - sparse_categorical_accuracy: 0.7041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.045106053352356, 0.7041000127792358]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=optimizer_init_fn(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=70, epochs=10, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_conv_net_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_98 (Bat  multiple                 12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          multiple                  896       \n",
      "                                                                 \n",
      " batch_normalization_99 (Bat  multiple                 128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  multiple                 0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           multiple                  320400    \n",
      "                                                                 \n",
      " dense_146 (Dense)           multiple                  160400    \n",
      "                                                                 \n",
      " dense_147 (Dense)           multiple                  160400    \n",
      "                                                                 \n",
      " dense_148 (Dense)           multiple                  4010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646,246\n",
      "Trainable params: 646,176\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
