# Курс "Нейронные сети и глубокое обучение" Самарского Университета
Лектор Артем Владимирович Никоноров, д.т.н., artniko@gmail.com  
Ассистент Виктория Витальевна Евдокимова, аспирант Самарского Университета, vkutikova94@gmail.com


Курс основывается на предыдущих более обзорных лекциях и туториалах по глубокому обучению и его приложениях, в частности, вот [небольшая обзорная лекция](https://youtu.be/Gpq1PFUee88) в Кавказком Математическом Центре. Также во многом этот курс является адаптацией известнейшего курса http://cs231n.stanford.edu/  

## Предварительный график проведения курса.

**Первая лекция в 14-00 МСК 14.09.2020 в Zoom.**  
Ссылка будет размещена позднее.

Предположительно, лекции будут вестись по две в две недели по понедельникам.
Возможен переход на одну пару еженедельно.

## Предварительный лекционный план.

План может менятся в процессе курса.  

**Лекция 1. Классификация, основанная на данных**   
Введение в курс.  
Задача классификации изображений.  
Подходы основанные на данных.  
Линейная классификация и knn-классификатор.  

**Лекция 2. Функции потерь и оптимизация.**  
Мультиклассовый SVM и его функция потерь.  
Софтмакс и мультимодальная логистическая регрессия.  
Оптимизация функции потерь.  
Стохастический градиентный спуск.  

**Лекция 3. Нейронные сети и обратное распространение ошибки.**  
Алгоритм обратного распространения ошибки.  
Многослойный перцептрон.  
Классификация с точки зрения нейронной сети.  

**Лекция 4. Сверточные сети (СНС).**  
История.  
Основные операции СНС.  
Применение СНС вне задач машинного зрения.  

**Лекция 5. Инструментарий глубокого обучения.**  
CPU vs GPU vs TPU.  
Пакеты глубокого обучения, Tensorflow, Keras и другие.  
Вычислительные графы СНС.  

**Лекция 6. Обучение СНС, часть 1.**  
Активационные функции, обработка данных сетью.  
Пакетная нормализация и другие трюки.  
Transfer learning.

**Лекция 7. Обучение СНС, часть 2.**  
Политики обновления гиперпараметров.  
Тюнинг процесса обучения.
Аугментация данных.  

**Лекция 8. Архитектуры СНС**  
Базовые архитектуры - AlexNet, VGG, GoogleNet, ResNet, UNET и другие.  

**Лекция 9. Генеративные и рекуррентные модели**  
RNN/LSTM.  
Механизм attention.
Обработка естественного языка.
GAN сети.

**Лекция 10. Прикладные сценарии использования СНС**  
TBD.  

**Лекция 11. Перспективы развития ИИ**  
TBD.  

## Предварительный план лабораторных работ.

План может менятся в процессе курса.  

**Л.Р. 1**  
kNN, многоклассовый SVM, SoftMax.  
[Материалы к лабораторной](https://github.com/da0c/DL_Course_SamU/tree/master/lab_1).

**Л.Р. 2**  
Двухслойная сеть.

**Л.Р. 3**  
Многослойный перцептрон, обратное распространение ошибки, сверточные сети.

**Л.Р. 4**  
Использование различных архитектуры СНС в Tensorflow/Keras.

**Л.Р. 5**  
Решение прикладной задачи с применением СНС.








